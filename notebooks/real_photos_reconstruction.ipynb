{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmf07LU3tYfXuLxGtS9D8t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgemar723/3DObjectReconstruction/blob/main/notebooks/real_photos_reconstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVyvcYmpU8Cm"
      },
      "outputs": [],
      "source": [
        "# Library imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import trimesh\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload photos from your device\n",
        "print(\"Please upload 10-20 photos of your object (taken from different angles):\")\n",
        "print(\"Tips: Good lighting, avoid blur, walk around the object in a circle\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Create directory and save files\n",
        "os.makedirs('real_object_views', exist_ok=True)\n",
        "\n",
        "image_files = []\n",
        "for filename in sorted(uploaded.keys()):\n",
        "    filepath = f'real_object_views/{filename}'\n",
        "    with open(filepath, 'wb') as f:\n",
        "        f.write(uploaded[filename])\n",
        "    image_files.append(filepath)\n",
        "\n",
        "print(f\"\\n✓ Successfully uploaded {len(image_files)} images\")\n",
        "print(\"Image files:\", image_files)"
      ],
      "metadata": {
        "id": "weDZD0y6pUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load first two images for reconstruction\n",
        "if len(image_files) < 2:\n",
        "    raise ValueError(\"Need at least 2 images for reconstruction!\")\n",
        "\n",
        "img1 = cv2.imread(image_files[0])\n",
        "img2 = cv2.imread(image_files[1])\n",
        "\n",
        "# Convert to RGB for display (OpenCV loads as BGR)\n",
        "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the images\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "axes[0].imshow(img1_rgb)\n",
        "axes[0].set_title('Image 1')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(img2_rgb)\n",
        "axes[1].set_title('Image 2')\n",
        "axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Convert to grayscale for processing\n",
        "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "print(f\"Image 1 shape: {gray1.shape}\")\n",
        "print(f\"Image 2 shape: {gray2.shape}\")"
      ],
      "metadata": {
        "id": "uhS9G-jRprkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SIFT detector\n",
        "sift = cv2.SIFT_create()\n",
        "\n",
        "# Detect keypoints and compute descriptors\n",
        "keypoints1, descriptors1 = sift.detectAndCompute(gray1, None)\n",
        "keypoints2, descriptors2 = sift.detectAndCompute(gray2, None)\n",
        "\n",
        "print(f\"✓ Detected {len(keypoints1)} keypoints in image 1\")\n",
        "print(f\"✓ Detected {len(keypoints2)} keypoints in image 2\")\n",
        "\n",
        "# Visualize keypoints\n",
        "img1_keypoints = cv2.drawKeypoints(gray1, keypoints1, None,\n",
        "                                    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "img2_keypoints = cv2.drawKeypoints(gray2, keypoints2, None,\n",
        "                                    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
        "axes[0].imshow(img1_keypoints)\n",
        "axes[0].set_title(f'Image 1 - {len(keypoints1)} keypoints')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(img2_keypoints)\n",
        "axes[1].set_title(f'Image 2 - {len(keypoints2)} keypoints')\n",
        "axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Lc-SqzN0qw6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create projection matrices\n",
        "P1 = K @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
        "P2 = K @ np.hstack([R, t])\n",
        "\n",
        "# Triangulate points\n",
        "inliers = mask.ravel().tolist()\n",
        "points1_tri = points1[inliers].T\n",
        "points2_tri = points2[inliers].T\n",
        "points_4d = cv2.triangulatePoints(P1, P2, points1_tri, points2_tri)\n",
        "\n",
        "# Convert to 3D\n",
        "points_3d = points_4d[:3] / points_4d[3]\n",
        "points_3d = points_3d.T\n"
      ],
      "metadata": {
        "id": "zCrfc90Zq6lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create brute force matcher\n",
        "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
        "\n",
        "# Match descriptors between two images\n",
        "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "# Apply Lowe's ratio test\n",
        "good_matches = []\n",
        "for m, n in matches:\n",
        "    if m.distance < 0.75 * n.distance:\n",
        "        good_matches.append(m)\n",
        "\n",
        "print(f\"✓ Found {len(matches)} initial matches\")\n",
        "print(f\"✓ {len(good_matches)} good matches after ratio test\")\n",
        "\n",
        "# Visualize matches\n",
        "img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2,\n",
        "                              good_matches, None,\n",
        "                              flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.imshow(img_matches)\n",
        "plt.title(f'Feature Matches: {len(good_matches)} good matches')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3XSZf18kq7QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract matched point coordinates\n",
        "points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches])\n",
        "points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches])\n",
        "\n",
        "# Estimate camera intrinsics\n",
        "h, w = gray1.shape\n",
        "focal_length = w  # rough estimate\n",
        "principal_point = (w/2, h/2)\n",
        "\n",
        "K = np.array([[focal_length, 0, principal_point[0]],\n",
        "              [0, focal_length, principal_point[1]],\n",
        "              [0, 0, 1]], dtype=np.float32)\n",
        "\n",
        "print(\"Camera intrinsic matrix K:\")\n",
        "print(K)\n",
        "\n",
        "# Find essential matrix using RANSAC\n",
        "E, mask = cv2.findEssentialMat(points1, points2, K,\n",
        "                                method=cv2.RANSAC,\n",
        "                                prob=0.999,\n",
        "                                threshold=1.0)\n",
        "\n",
        "# Count inliers\n",
        "num_inliers = np.sum(mask)\n",
        "inlier_rate = num_inliers / len(good_matches) * 100\n",
        "\n",
        "print(f\"\\n✓ Essential matrix computed\")\n",
        "print(f\"✓ Inliers: {num_inliers}/{len(good_matches)} ({inlier_rate:.1f}%)\")\n",
        "\n",
        "# Recover rotation and translation\n",
        "_, R, t, mask_pose = cv2.recoverPose(E, points1, points2, K)\n",
        "\n",
        "print(f\"\\nRotation matrix R:\")\n",
        "print(R)\n",
        "print(f\"\\nTranslation vector t:\")\n",
        "print(t.ravel())\n",
        "print(f\"\\nRotation determinant (should be ~1): {np.linalg.det(R):.4f}\")\n"
      ],
      "metadata": {
        "id": "4JkQVwpVq-CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create projection matrices\n",
        "P1 = K @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
        "P2 = K @ np.hstack([R, t])\n",
        "\n",
        "print(\"Projection matrix P1:\")\n",
        "print(P1)\n",
        "print(\"\\nProjection matrix P2:\")\n",
        "print(P2)\n",
        "\n",
        "# Get inlier points\n",
        "inliers = mask.ravel().astype(bool)\n",
        "points1_inliers = points1[inliers]\n",
        "points2_inliers = points2[inliers]\n",
        "\n",
        "print(f\"\\n✓ Triangulating {len(points1_inliers)} inlier points...\")\n",
        "\n",
        "# Triangulate points\n",
        "points_4d = cv2.triangulatePoints(P1, P2,\n",
        "                                   points1_inliers.T,\n",
        "                                   points2_inliers.T)\n",
        "\n",
        "# Convert from homogeneous to 3D\n",
        "points_3d = points_4d[:3] / points_4d[3]\n",
        "points_3d = points_3d.T\n",
        "\n",
        "print(f\"✓ Reconstructed {len(points_3d)} 3D points\")\n",
        "print(f\"\\n3D point cloud statistics:\")\n",
        "print(f\"  X range: [{points_3d[:, 0].min():.2f}, {points_3d[:, 0].max():.2f}]\")\n",
        "print(f\"  Y range: [{points_3d[:, 1].min():.2f}, {points_3d[:, 1].max():.2f}]\")\n",
        "print(f\"  Z range: [{points_3d[:, 2].min():.2f}, {points_3d[:, 2].max():.2f}]\")\n"
      ],
      "metadata": {
        "id": "GNBuo8t3oXlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create 3D plot\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot 3D points\n",
        "ax.scatter(points_3d[:, 0], points_3d[:, 1], points_3d[:, 2],\n",
        "           c='blue', marker='o', s=50, alpha=0.6, label='3D Points')\n",
        "\n",
        "# Plot camera positions\n",
        "ax.scatter(0, 0, 0, c='red', marker='^', s=200, label='Camera 1')\n",
        "ax.scatter(t[0], t[1], t[2], c='green', marker='^', s=200, label='Camera 2')\n",
        "\n",
        "# Labels and legend\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title(f'3D Reconstruction ({len(points_3d)} points)')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hmwhYQePob-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create point cloud mesh\n",
        "points_mesh = trimesh.points.PointCloud(vertices=points_3d)\n",
        "\n",
        "# Export to PLY\n",
        "output_filename = 'real_object_reconstruction.ply'\n",
        "points_mesh.export(output_filename)\n",
        "\n",
        "print(f\"✓ Point cloud exported to: {output_filename}\")\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)\n",
        "print(\"✓ File ready for download!\")\n"
      ],
      "metadata": {
        "id": "yl406EcgpD_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print final summary\n",
        "print(\"=\"*50)\n",
        "print(\"RECONSTRUCTION SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Images processed: {image_files[0]} and {image_files[1]}\")\n",
        "print(f\"Keypoints detected: {len(keypoints1)} and {len(keypoints2)}\")\n",
        "print(f\"Feature matches: {len(good_matches)}\")\n",
        "print(f\"Inliers after RANSAC: {num_inliers} ({inlier_rate:.1f}%)\")\n",
        "print(f\"3D points reconstructed: {len(points_3d)}\")\n",
        "print(f\"Output file: {output_filename}\")\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "id": "uGTA-HhnpHu9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
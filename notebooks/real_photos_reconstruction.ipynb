{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYk0R15HAmIw7Mln7H5R4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgemar723/3DObjectReconstruction/blob/main/notebooks/real_photos_reconstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVyvcYmpU8Cm"
      },
      "outputs": [],
      "source": [
        "#Library imports and set up\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import trimesh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to greyscale\n",
        "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "sift = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "\n",
        "img_keypoints = cv2.drawKeypoints(gray, keypoints, None,\n",
        "                                   flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)"
      ],
      "metadata": {
        "id": "weDZD0y6pUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create brute force matcher\n",
        "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
        "\n",
        "# Match descriptors between two images\n",
        "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "# Apply ratio test (Lowe's ratio test)\n",
        "good_matches = []\n",
        "for m, n in matches:\n",
        "    if m.distance < 0.75 * n.distance:\n",
        "        good_matches.append(m)\n",
        "\n",
        "# Draw matches\n",
        "img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2,\n",
        "                              good_matches, None,\n",
        "                              flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n"
      ],
      "metadata": {
        "id": "uhS9G-jRprkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract matched point coordinates\n",
        "points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches])\n",
        "points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches])\n",
        "\n",
        "# Camera intrinsics (adjust for image size)\n",
        "h, w = gray1.shape\n",
        "focal_length = w  # rough estimate\n",
        "principal_point = (w/2, h/2)\n",
        "\n",
        "K = np.array([[focal_length, 0, principal_point[0]],\n",
        "              [0, focal_length, principal_point[1]],\n",
        "              [0, 0, 1]], dtype=np.float32)\n",
        "\n",
        "# Find essential matrix using RANSAC\n",
        "E, mask = cv2.findEssentialMat(points1, points2, K, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
        "\n",
        "# Recover rotation and translation\n",
        "_, R, t, mask_pose = cv2.recoverPose(E, points1, points2, K)\n"
      ],
      "metadata": {
        "id": "Lc-SqzN0qw6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create projection matrices\n",
        "P1 = K @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
        "P2 = K @ np.hstack([R, t])\n",
        "\n",
        "# Triangulate points\n",
        "inliers = mask.ravel().tolist()\n",
        "points1_tri = points1[inliers].T\n",
        "points2_tri = points2[inliers].T\n",
        "points_4d = cv2.triangulatePoints(P1, P2, points1_tri, points2_tri)\n",
        "\n",
        "# Convert to 3D\n",
        "points_3d = points_4d[:3] / points_4d[3]\n",
        "points_3d = points_3d.T\n"
      ],
      "metadata": {
        "id": "zCrfc90Zq6lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 3D plot\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(points_3d[:, 0], points_3d[:, 1], points_3d[:, 2],\n",
        "           c='blue', marker='o', s=50, alpha=0.6)\n",
        "\n",
        "# Plot camera positions\n",
        "ax.scatter(0, 0, 0, c='red', marker='^', s=200, label='Camera 1')\n",
        "ax.scatter(t[0], t[1], t[2], c='green', marker='^', s=200, label='Camera 2')\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3XSZf18kq7QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import trimesh\n",
        "\n",
        "# Create point cloud\n",
        "points_mesh = trimesh.points.PointCloud(vertices=points_3d)\n",
        "\n",
        "# Export\n",
        "points_mesh.export('reconstruction.ply')\n"
      ],
      "metadata": {
        "id": "4JkQVwpVq-CB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}